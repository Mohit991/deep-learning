{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist using CNN",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "y4IMRB1ep7wJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "#download mnist data and split into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "(X_tt, y_tt), (X_t, y_t) = mnist.load_data()\n",
        "# second is just to keep the original form of the images \n",
        "# as we are going to make changes to the images  now\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ANy8GAHxqJSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "2eae214c-63ba-4c35-fdd9-ac30b0dea624"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc9ddee7550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc9ddfd0c18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xZ7UoCddqOM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b021913e-d994-4b01-85d6-e443d8984acb"
      },
      "cell_type": "code",
      "source": [
        "#check image shape\n",
        "X_train[0].shape\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "hXmtEi5iqZW9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# By default, the shape of every image in the mnist dataset is 28 x 28, so we will not need to check the shape of all the images.\n",
        "# When using real-world datasets, you may not be so lucky.\n",
        "# 28 x 28 is also a fairly small size, so the CNN will be able to run over each image pretty quickly.\n",
        "\n",
        "\n",
        "\n",
        "# Data pre-processing\n",
        "\n",
        "# Next, we need to reshape our dataset inputs (X_train and X_test) to the shape that our model expects when we train the model. \n",
        "# The first number is the number of images (60,000 for X_train and 10,000 for X_test).\n",
        "# Then comes the shape of each image (28x28). The last number is 1, which signifies that the images are greyscale.\n",
        "#reshape data to fit model\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CmwW45CXq2CT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0188db3-1ab6-42ed-fa84-82ab9edae0d5"
      },
      "cell_type": "code",
      "source": [
        "# We need to ‘one-hot-encode’ our target variable. This means that a column will be\n",
        "# created for each output category and a binary variable is inputted for each category.\n",
        "# For example, we saw that the first image in the dataset is a 5.\n",
        "# This means that the sixth number in our array will have a 1 and the rest of the array will be filled with 0.\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#one-hot encode target column\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "Ya3iyoR_rDYA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "\n",
        "# Now we are ready to build our model. Here is the code:\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "#create model\n",
        "model = Sequential()\n",
        "\n",
        "#add model layers\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# The model type that we will be using is Sequential. \n",
        "# Sequential is the easiest way to build a model in Keras. \n",
        "# It allows you to build a model layer by layer.\n",
        "\n",
        "# We use the ‘add()’ function to add layers to our model.\n",
        "\n",
        "# Our first 2 layers are Conv2D layers.\n",
        "# These are convolution layers that will deal with our input images, which are seen as 2-dimensional matrices.\n",
        "\n",
        "# 64 in the first layer and 32 in the second layer are the number of nodes in each layer.\n",
        "# This number can be adjusted to be higher or lower, depending on the size of the dataset. In our case,\n",
        "# 64 and 32 work well, so we will stick with this for now.\n",
        "\n",
        "# Kernel size is the size of the filter matrix for our convolution.\n",
        "# So a kernel size of 3 means we will have a 3x3 filter matrix.\n",
        "\n",
        "# Activation is the activation function for the layer.\n",
        "# The activation function we will be using for our first 2 layers is the ReLU, or Rectified Linear Activation.\n",
        "# This activation function has been proven to work well in neural networks.\n",
        "\n",
        "# Our first layer also takes in an input shape.\n",
        "# This is the shape of each input image, 28,28,1 as seen earlier on,\n",
        "# with the 1 signifying that the images are greyscale.\n",
        "\n",
        "# In between the Conv2D layers and the dense layer,\n",
        "# there is a ‘Flatten’ layer. Flatten serves as a connection between the convolution and dense layers.\n",
        "\n",
        "# ‘Dense’ is the layer type we will use in for our output layer. \n",
        "# Dense is a standard layer type that is used in many cases for neural networks.\n",
        "\n",
        "# We will have 10 nodes in our output layer, one for each possible outcome (0–9).\n",
        "\n",
        "# The activation is ‘softmax’. \n",
        "# Softmax makes the output sum up to 1 so the output can be interpreted as probabilities.\n",
        "# The model will then make its prediction based on which option has the highest probability."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMQ1Dzs4r95m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The optimizer controls the learning rate. We will be using ‘adam’ as our optmizer.\n",
        "# Adam is generally a good optimizer to use for many cases. The adam optimizer adjusts the learning rate throughout training.\n",
        "\n",
        "# The learning rate determines how fast the optimal weights for the model are calculated.\n",
        "# A smaller learning rate may lead to more accurate weights (up to a certain point), but the time it takes to compute the weights will be longer.\n",
        "\n",
        "# We will use ‘categorical_crossentropy’ for our loss function.\n",
        "# This is the most common choice for classification. A lower score indicates that the model is performing better.\n",
        "\n",
        "# To make things even easier to interpret, we will use the ‘accuracy’ metric\n",
        "# to see the accuracy score on the validation set when we train the model.\n",
        "#compile model using accuracy to measure model performance\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7THjZwONs_10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "2419c9d6-50b7-41b3-c639-c070ef3cee4a"
      },
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "\n",
        "# Now we will train our model. \n",
        "# To train, we will use the ‘fit()’ function on our model with the following parameters:\n",
        "#   training data (train_X), target data (train_y), validation data, and the number of epochs.\n",
        "\n",
        "# For our validation data, we will use the test set provided to us in our dataset, \n",
        "# which we have split into X_test and y_test.\n",
        "\n",
        "# The number of epochs is the number of times the model will cycle through the data.\n",
        "# The more epochs we run, the more the model will improve, up to a certain point.\n",
        "# After that point, the model will stop improving during each epoch. For our model,\n",
        "# we will set the number of epochs to 3.\n",
        "\n",
        "#train the model\n",
        "model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=3)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 204s 3ms/step - loss: 8.2296 - acc: 0.4863 - val_loss: 6.8152 - val_acc: 0.5754\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 202s 3ms/step - loss: 6.7715 - acc: 0.5789 - val_loss: 6.8417 - val_acc: 0.5743\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 203s 3ms/step - loss: 5.9197 - acc: 0.6321 - val_loss: 5.2429 - val_acc: 0.6743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc9ddf42d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "pRfg4LxszwR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "f7b0cb29-adc0-4f35-bc80-0e7d22495f22"
      },
      "cell_type": "code",
      "source": [
        "# Using our model to make predictions\n",
        "\n",
        "# If you want to see the actual predictions that our model has made for the test data,\n",
        "# we can use the predict function. The predict function will give an array with 10 numbers. \n",
        "# These numbers are the probabilities that the input image represents each digit (0–9).\n",
        "# The array index with the highest number represents the model prediction. The sum of each array equals 1 (since each number is a probability).\n",
        "\n",
        "# To show this, we will show the predictions for the first 4 images in the test set.\n",
        "\n",
        "# Note: If we have new data, we can input our new data into the predict function to see\n",
        "#   the predictions our model makes on the new data. Since we don’t have any new unseen data, \n",
        "#   we will show predictions using the test set for now.\n",
        "\n",
        "#predict first 4 images in the test set\n",
        "model.predict(X_test[:4])\n",
        "# it says first is 7, second is 2, third is 1, fourth is 0."
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "0MAI4O2y0CD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "0b44fba5-c170-4bdd-bc7b-e8c9b436e17b"
      },
      "cell_type": "code",
      "source": [
        "#actual results for first 4 images in test set\n",
        "import matplotlib.pyplot as plt\n",
        "#plot the first image in the dataset\n",
        "plt.imshow(X_t[3])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc9dd9c8b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEJYAYEBYAoABYQkABoQlABj8H6FSMzjdMvGaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc9dd9fe908>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}